{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "https://www.geekering.com/categories/computer-vision/marcellacavalcanti/hand-tracking-and-finger-counting-in-python-with-mediapipe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tkinter import messagebox\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Initially set finger count to 0 for each cap\n",
    "    fingerCount = 0\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        # Get hand index to check label (left or right)\n",
    "        handIndex = results.multi_hand_landmarks.index(hand_landmarks)\n",
    "        handLabel = results.multi_handedness[handIndex].classification[0].label\n",
    "\n",
    "        # Set variable to keep landmarks positions (x and y)\n",
    "        handLandmarks = []\n",
    "\n",
    "        # Fill list with x and y positions of each landmark\n",
    "        for landmarks in hand_landmarks.landmark:\n",
    "          handLandmarks.append([landmarks.x, landmarks.y])\n",
    "\n",
    "        # Test conditions for each finger: Count is increased if finger is \n",
    "        #   considered raised.\n",
    "        # Thumb: TIP x position must be greater or lower than IP x position, \n",
    "        #   deppeding on hand label.\n",
    "        if handLabel == \"Left\" and handLandmarks[4][0] > handLandmarks[3][0]:\n",
    "          fingerCount = fingerCount+1\n",
    "        elif handLabel == \"Right\" and handLandmarks[4][0] < handLandmarks[3][0]:\n",
    "          fingerCount = fingerCount+1\n",
    "\n",
    "        # Other fingers: TIP y position must be lower than PIP y position, \n",
    "        #   as image origin is in the upper left corner.\n",
    "        if handLandmarks[8][1] < handLandmarks[6][1]:       #Index finger\n",
    "          fingerCount = fingerCount+1\n",
    "        if handLandmarks[12][1] < handLandmarks[10][1]:     #Middle finger\n",
    "          fingerCount = fingerCount+1\n",
    "        if handLandmarks[16][1] < handLandmarks[14][1]:     #Ring finger\n",
    "          fingerCount = fingerCount+1\n",
    "        if handLandmarks[20][1] < handLandmarks[18][1]:     #Pinky\n",
    "          fingerCount = fingerCount+1\n",
    "\n",
    "        # Draw hand landmarks \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Display finger count\n",
    "    cv2.putText(image, str(fingerCount), (50, 450), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 0, 0), 10)\n",
    "\n",
    "    # Display image\n",
    "    cv2.imshow('MediaPipe Hands', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "    if fingerCount == 10:\n",
    "      cap.release()\n",
    "\n",
    "\n",
    "# cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def skinmask(img):\n",
    "    hsvim = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "    upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "    skinRegionHSV = cv.inRange(hsvim, lower, upper)\n",
    "    blurred = cv.blur(skinRegionHSV, (2,2))\n",
    "    ret, thresh = cv.threshold(blurred,0,255,cv.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "def getcnthull(mask_img):\n",
    "    contours, hierarchy = cv.findContours(mask_img, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = max(contours, key=lambda x: cv.contourArea(x))\n",
    "    hull = cv.convexHull(contours)\n",
    "    return contours, hull\n",
    "\n",
    "def getdefects(contours):\n",
    "    hull = cv.convexHull(contours, returnPoints=False)\n",
    "    defects = cv.convexityDefects(contours, hull)\n",
    "    return defects\n",
    "\n",
    "    \n",
    "cap = cv.VideoCapture(0) # '0' for webcam\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    try:\n",
    "        mask_img = skinmask(img)\n",
    "        contours, hull = getcnthull(mask_img)\n",
    "        cv.drawContours(img, [contours], -1, (255,255,0), 2)\n",
    "        cv.drawContours(img, [hull], -1, (0, 255, 255), 2)\n",
    "        defects = getdefects(contours)\n",
    "        if defects is not None:\n",
    "            cnt = 0\n",
    "            for i in range(defects.shape[0]):  # calculate the angle\n",
    "                s, e, f, d = defects[i][0]\n",
    "                start = tuple(contours[s][0])\n",
    "                end = tuple(contours[e][0])\n",
    "                far = tuple(contours[f][0])\n",
    "                a = np.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
    "                b = np.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)\n",
    "                c = np.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)\n",
    "                angle = np.arccos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  #      cosine theorem\n",
    "                if angle <= np.pi / 2:  # angle less than 90 degree, treat as fingers\n",
    "                    cnt += 1\n",
    "                    cv.circle(img, far, 4, [0, 0, 255], -1)\n",
    "            if cnt > 0:\n",
    "                cnt = cnt+1\n",
    "            cv.putText(img, str(cnt), (0, 50), cv.FONT_HERSHEY_SIMPLEX,1, (255, 0, 0) , 2, cv.LINE_AA)\n",
    "        cv.imshow(\"img\", img)\n",
    "    except:\n",
    "        pass\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"data/people_walking.jpeg\", 0) # read as gray scale\n",
    "blurred = cv2.GaussianBlur(im, (7, 7), 1.166) # apply gaussian blur to the image\n",
    "blurred_sq = blurred * blurred\n",
    "sigma = cv2.GaussianBlur(im * im, (7, 7), 1.166)\n",
    "sigma = (sigma - blurred_sq) ** 0.5\n",
    "sigma = sigma + 1.0/255 # to make sure the denominator doesn't give DivideByZero Exception\n",
    "structdis = (im - blurred)/sigma # final MSCN(i, j) image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(structdis\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m(i \u001b[39m+\u001b[39m reqshift[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i \u001b[39m+\u001b[39m reqshift[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m structdis\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mand\u001b[39;00m j \u001b[39m+\u001b[39m reqshift[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m j  \u001b[39m+\u001b[39m reqshift[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m structdis\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m---> 12\u001b[0m        ShiftArr[i, j] \u001b[39m=\u001b[39m OrigArr[i \u001b[39m+\u001b[39m reqshift[\u001b[39m0\u001b[39m], j \u001b[39m+\u001b[39m reqshift[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     13\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m        ShiftArr[i, j] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# indices to calculate pair-wise products (H, V, D1, D2)\n",
    "shifts = [[0,1], [1,0], [1,1], [-1,1]]\n",
    "# calculate pairwise components in each orientation\n",
    "for itr_shift in range(1, len(shifts) + 1):\n",
    "    OrigArr = structdis\n",
    "    reqshift = shifts[itr_shift-1] # shifting index\n",
    "    ShiftArr = reqshift\n",
    " \n",
    "    for i in range(structdis.shape[0]):\n",
    "        for j in range(structdis.shape[1]):\n",
    "            if(i + reqshift[0] >= 0 and i + reqshift[0] < structdis.shape[0] and j + reqshift[1] >= 0 and j  + reqshift[1] < structdis.shape[1]):\n",
    "               ShiftArr[i, j] = OrigArr[i + reqshift[0], j + reqshift[1]]\n",
    "            else:\n",
    "               ShiftArr[i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
